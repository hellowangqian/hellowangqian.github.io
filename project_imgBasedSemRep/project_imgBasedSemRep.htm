<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License

Name       : Accumen
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20120712
-->
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<title>Alternative Semantic Representations for Zero-Shot Human Action Recognition</title>
		<link href="http://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css" />
		<link href="http://fonts.googleapis.com/css?family=Kreon" rel="stylesheet" type="text/css" />
		<link rel="stylesheet" type="text/css" href="style.css" />
    <style type="text/css">
    div {
}
    </style>
	</head>
	<body>
		<div id="wrapper">
			<div id="header">
			  <div id="logo">
			    <h2>Alternative Semantic Representations for Zero-Shot Human Action Recognition </h2>
			    <p>Qian Wang, Ke   Chen<p>
              </div>
		  </div>
			<div id="page">
			  <div id="content">
				  <div class="box">
						<h2>Introduction</h2>
						<p>A proper semantic representation for encoding side information is key to the success of zero-shot learning. In this paper, we explore two alternative semantic representations especially for zero-shot human action recognition:  textual descriptions of human actions and deep features extracted from still images relevant to human actions. Such side information are accessible on Web with little cost, which paves a new way in gaining side information for large-scale zero-shot human action recognition. We investigate different encoding methods to generate semantic representations for human actions from such side information. Based on our zero-shot visual recognition method, we conducted experiments on UCF101 and HMDB51 to evaluate two proposed semantic representations . The results suggest that our proposed text- and image-based semantic representations outperform traditional attributes and word vectors considerably for zero-shot human action recognition. In particular, the image-based semantic representations yield the favourable performance even though the representation is extracted from a small number of images per class.</p>
				</div>
					<div class="box">
						<h3>framework</h3>
						<p><img src="image001.png" alt="" width="680" height="320" /></p>
<p>&nbsp;</p>
					</div>
					<div class="box">
						<h2>Side Information Collection</h2>
                      <p><img src="image002.png" alt="" width="701" height="409" /></p>
					</div>
                    
                <div class="box">
				  <h2>Experimental Results</h2>
                  <p><img src="image003.png" alt="" width="700" height="350" /></p>
                  <p><img src="image004.png" alt="" width="700" height="350" /></p>
				  </div>
                  
                <div> 
                  <h2> Codes and Data </h2>
                  <p>If you are interested in our work, the codes and data (e.g., pre-computed visual representations, semantic representations used in our experiments) are available upon request. The details of the codes and data are described <a href="readme.txt">here</a>.</p>
				  <p><a href="https://www.dropbox.com/s/1amth1my38f4ujn/data.zip?dl=0">[download data]</a>   <a href="https://www.dropbox.com/s/xjc1haf0bqqyn1f/imageScraper.zip?dl=0">[download imageScraperTool]</a> </p>
                  <p><a href="mailto:Qian.wang@manchester.ac.uk">Qian.wang@manchester.ac.uk</a></p>
                </div>
                
                <p>&nbsp;</p>
                <div>
                  <h2>Related Paper</h2>
                <p>Wang,   Q., &amp; Chen, K. (2017). Alternative Semantic Representations for Zero-Shot Human Action Recognition.Â ECML-PKDD 2017.</p>            

	</body>
</html>